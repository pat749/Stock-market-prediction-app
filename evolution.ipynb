{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evolution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "10u32iHqoiFS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evolution Algorithm"
      ]
    },
    {
      "metadata": {
        "id": "rSYHjesZ7zwL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setup Google Colaboratory\n",
        "!mkdir models\n",
        "!mkdir data\n",
        "!mkdir data/stock_prices\n",
        "!mkdir evolution_model_graphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ND9zF0qwor7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "metadata": {
        "id": "Vsm09yqq7BRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xl_VY9ib7BRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from build_dataset import build_training_dataset, get_stock_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgRhogiS7BRZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models.dnn_regression import DenseNeuralNetwork"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1o4RjWV7BRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.backend import clear_session\n",
        "from keras.utils import plot_model\n",
        "from hashlib import sha256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2_9V9XMo1vO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get last run data"
      ]
    },
    {
      "metadata": {
        "id": "1MGLsRIBez9Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "last_run = None\n",
        "if path.isfile(\"last_run.json\"):\n",
        "    with open(\"last_run.json\", \"r\") as last_run_file:\n",
        "        last_run = json.load(last_run_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VqZrq0Ao9UK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize models"
      ]
    },
    {
      "metadata": {
        "id": "KnolKvF0v1bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "population = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cT2JzudwbEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "POPULATION_SIZE = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jcMoglfm6pt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_options = {\n",
        "    \"config\": [\n",
        "        {\"type\": \"lookback\", \"n\": 22, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 5, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 10, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 30, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 90, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 180, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"},\n",
        "        {\"type\": \"moving_avg\", \"n\": 365, \"stock_code\": \"GOOGL\", \"column\": \"adjusted_close\"}\n",
        "    ],\n",
        "    \"stock_codes\": [\"GOOGL\"],\n",
        "    \"stock_code\": \"GOOGL\",\n",
        "    \"column\": \"adjusted_close\"\n",
        "}\n",
        "print(sha256(json.dumps(input_options).encode()).hexdigest())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBvFzVnHm81y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stock_code = \"GOOGL\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "unKNOkcGv7kU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if last_run is not None:\n",
        "    population = [DenseNeuralNetwork(\n",
        "        model[\"model_options\"],\n",
        "        model[\"input_options\"],\n",
        "        model[\"stock_code\"],\n",
        "        build_model=False\n",
        "    ) for model in last_run[\"population\"]]\n",
        "else:\n",
        "    init_model_options = DenseNeuralNetwork.random_model_options(POPULATION_SIZE, \"dense\")\n",
        "    for i in range(POPULATION_SIZE):\n",
        "        population.append(DenseNeuralNetwork(\n",
        "            init_model_options[i],\n",
        "            input_options,\n",
        "            stock_code,\n",
        "            build_model=False\n",
        "        ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFUkywFfCtzX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Stock Data"
      ]
    },
    {
      "metadata": {
        "id": "yyD_pI8lCwqe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stock_data = get_stock_data(input_options[\"stock_codes\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zf9pgSy7qvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize errors"
      ]
    },
    {
      "metadata": {
        "id": "O2c2ptKhwzgt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "error_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VSaKqj9Kw9RE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if last_run is not None:\n",
        "    errors = last_run[\"errors\"]\n",
        "    error_history = last_run[\"error_history\"]\n",
        "else:\n",
        "    for model_idx, model in enumerate(population):\n",
        "        print(\"Initial model {}\".format(model_idx + 1))\n",
        "        \n",
        "        # reset session graph\n",
        "        clear_session()\n",
        "        \n",
        "        # build the model\n",
        "        model.build_model()\n",
        "        \n",
        "        # prepare the data\n",
        "        x, y, other_data = build_training_dataset(model.input_options, model.model_options[\"predict_n\"], stock_data=stock_data)\n",
        "        # split the data into training set and testing set\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "        # train the model\n",
        "        model.train(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            verbose=0,\n",
        "            callbacks=[TensorBoard(log_dir=\"./evolution_tensorboard_logs/initial_{}\".format(model_idx + 1))]\n",
        "        )\n",
        "        # calculate the model error\n",
        "        error = model.model.evaluate(x_test, y_test, verbose=0)\n",
        "        errors.append(error[-1])\n",
        "    error_history = [errors]\n",
        "\n",
        "errors = np.array(errors)\n",
        "error_history = np.array(error_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x9PQkMB3pCI0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evolution algorithm"
      ]
    },
    {
      "metadata": {
        "id": "NMW7u9K3x_Ak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "last_iterations = last_run[\"last_iterations\"] if last_run is not None else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4zE5cEuxrv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ITERATIONS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mc7v70yRx9Tk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(last_iterations, last_iterations + ITERATIONS):\n",
        "    print(\"Iteration {}\".format(i + 1))\n",
        "    \n",
        "    # randomly choose 2 models\n",
        "    model_idxs = np.random.choice(np.arange(POPULATION_SIZE), size=2, replace=False)\n",
        "    \n",
        "    better_model_idx = -1\n",
        "    worse_model_idx = -1\n",
        "    if errors[model_idxs[0]] <= errors[model_idxs[1]]:\n",
        "        better_model_idx = model_idxs[0]\n",
        "        worse_model_idx = model_idxs[1]\n",
        "    else:\n",
        "        better_model_idx = model_idxs[1]\n",
        "        worse_model_idx = model_idxs[0]\n",
        "    \n",
        "    parent_model = population[better_model_idx]\n",
        "    \n",
        "    # kill and remove the worse model\n",
        "    population.pop(worse_model_idx)\n",
        "    errors = np.delete(errors, worse_model_idx)\n",
        "    \n",
        "    # reproduce the child model\n",
        "    child_model_options, mutation = DenseNeuralNetwork.evolve_model_options(parent_model.model_options)\n",
        "    print(\"Mutation: {}\".format(mutation))\n",
        "    child_model = DenseNeuralNetwork(\n",
        "        child_model_options,\n",
        "        input_options,\n",
        "        stock_code,\n",
        "        build_model=False\n",
        "    )\n",
        "    \n",
        "    # reset session graph\n",
        "    clear_session()\n",
        "\n",
        "    # build the model\n",
        "    child_model.build_model()\n",
        "    \n",
        "    # train the child model\n",
        "    # prepare the data\n",
        "    x, y, other_data = build_training_dataset(child_model.input_options, child_model.model_options[\"predict_n\"], stock_data=stock_data)\n",
        "    # split the data into training set and testing set\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "    # train the child model\n",
        "    child_model.train(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        verbose=0,\n",
        "        callbacks=[TensorBoard(log_dir=\"./evolution_tensorboard_logs/{}\".format(i + 1))]\n",
        "    )\n",
        "    # calculate the child model error\n",
        "    child_error = child_model.model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    # save the child model if it is the best model\n",
        "    if child_error[-1] < np.min(errors):\n",
        "        child_model.save_model(\"./model.h5\", DenseNeuralNetwork.KERAS_MODEL)\n",
        "    \n",
        "    # append the child model and its error\n",
        "    population.append(child_model)\n",
        "    errors = np.append(errors, child_error[-1])\n",
        "    error_history = np.append(error_history, [errors], axis=0)\n",
        "    \n",
        "    # plot the child model graph\n",
        "    plot_model(child_model.model, to_file=\"evolution_model_graphs/{}.png\".format(i + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_7IR0C1n5DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the best model\n",
        "best_model_idx = np.argmin(errors)\n",
        "best_model = population[best_model_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0VuGvIrpU0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Write this run data"
      ]
    },
    {
      "metadata": {
        "id": "BddjwKVnhEA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"last_run.json\", \"w\") as last_run_file:\n",
        "    json.dump({\n",
        "        \"last_iterations\": last_iterations + ITERATIONS,\n",
        "        \"population\": [{\n",
        "            \"model_options\": model.model_options,\n",
        "            \"input_options\": model.input_options,\n",
        "            \"stock_code\": model.stock_code\n",
        "        } for model in population],\n",
        "        \"errors\": errors.tolist(),\n",
        "        \"error_history\": error_history.tolist()\n",
        "    }, last_run_file, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u05LTKRF2wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -r evolution_tensorboard_logs.zip evolution_tensorboard_logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vpk7Do5-AF5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -r evolution_model_graphs.zip evolution_model_graphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21eBgYMZppxr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot evolution data"
      ]
    },
    {
      "metadata": {
        "id": "DVXFj0wx7BSI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zS1yg9e-7BSR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot evolution error history\n",
        "plt.scatter(\n",
        "    np.array([[i for _ in range(POPULATION_SIZE)] for i in range(error_history.shape[0])]).flatten(),\n",
        "    error_history.flatten()\n",
        ")\n",
        "plt.title(\"Population Mean Squared Error\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.xlabel(\"Iteration\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9mWPc2WToin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(\n",
        "    np.array([[i for _ in range(POPULATION_SIZE)] for i in range(error_history.shape[0])]).flatten(),\n",
        "    np.sqrt(error_history).flatten()\n",
        ")\n",
        "plt.title(\"Population Root Mean Squared Error\")\n",
        "plt.ylabel(\"Root Mean Squared Error\")\n",
        "plt.xlabel(\"Iteration\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cB-JdkuUCW-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(\n",
        "    np.arange(error_history.shape[0]),\n",
        "    np.min(error_history, axis=1)\n",
        ")\n",
        "plt.title(\"Population Minimum Mean Squared Error\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.xlabel(\"Iteration\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOua7Uv0C22M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(\n",
        "    np.arange(error_history.shape[0]),\n",
        "    np.min(np.sqrt(error_history), axis=1)\n",
        ")\n",
        "plt.title(\"Minimum Root Mean Squared Error\")\n",
        "plt.ylabel(\"Root Mean Squared Error\")\n",
        "plt.xlabel(\"Iteration\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gUKG8TFDAS1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}